# HEATMAP-GENERATION-FOR-RETAIL-STORES


Introduction:
This program uses OpenCV to process a video feed from a CCTV camera and generate a heatmap showing the areas with the most foot traffic. It performs background subtraction to isolate the foreground, then applies a Haar Cascade classifier at first and then used YOLOV5 to detect people in the image. The program accumulates the detections over time and generates a heatmap, with hotter areas indicating more foot traffic.

A heatmap is a visualization technique that represents the distribution of a particular feature or attribute over an image or region of interest (ROI). Heatmaps are often used to highlight areas of interest or activity, such as the concentration of people in a crowded area or the hotspots of a wildfire. In this code, a heatmap is generated to visualize the areas of activity where people are detected in a video frame. The heatmap is generated by accumulating the foreground masks generated by the background subtraction technique and applying a color map to the accumulated mask.

APPROACH 1

Import the required libraries - cv2 and NumPy.
Read in the input video file using cv2.VideoCapture().
Define the region of interest (ROI) for the store area. The program will only generate a heatmap for this area.
Create a background subtractor object using cv2.createBackgroundSubtractorMOG2(). This will subtract the background from the foreground to isolate moving objects.
Create an empty NumPy array to store the accumulated heatmap. The dimensions of the array correspond to the dimensions of the ROI.
Define a color map to use for the heatmap. In this example, we use the cv2.COLORMAP_HOT color map.
Load the Haar Cascade classifier for person detection using cv2.CascadeClassifier().
Create a named window for the video display using cv2.namedWindow().
Loop through the frames of the video using a while loop.
Read in a frame from the video using cap.read(). If there are no more frames, break out of the loop.
Crop the frame to the ROI using array slicing.
Apply background subtraction to the cropped frame using the background subtractor object.
Threshold the foreground mask to eliminate noise using cv2.threshold().
Detect people in the cropped frame using the Haar Cascade classifier and cv2.detectMultiScale().
Draw bounding boxes around the detected people using cv2.rectangle().
Update the heatmap by adding the thresholded mask to it.
Apply the color map to the heatmap using cv2.applyColorMap().
Set the gradient color to red by setting the blue and green channels to 0.
Merge the heatmap and the original frame using cv2.addWeighted().
Display the frame and the heatmap using cv2.imshow().
Check for user input to exit using cv2.waitKey(). If the user presses 'q', break out of the loop.
Release the video capture and close all windows using cap.release() and cv2.destroyAllWindows().

APPROACH 2

The necessary libraries are imported, including OpenCV, NumPy, and PyTorch.
The YOLOv5 model is loaded using the PyTorch hub.
A function is defined to generate a heat map from the detected humans.
The video file is opened using OpenCV's VideoCapture object.
A loop is set up to read each frame of the video file.
Each frame is converted from BGR to RGB format.
The YOLOv5 model is used to detect humans in the frame.
The generate_heatmap() function is called to create a heat map from the detected humans.
The heat map is overlaid onto the original frame and displayed in a window using OpenCV.
The loop continues until the video file ends or 'q' is pressed.
The video capture object is released and all windows are closed.


